{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mankirat/Library/Python/3.11/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.24.1)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.1-cp311-cp311-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.15.1-cp311-cp311-macosx_14_0_arm64.whl (24.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.8/24.8 MB\u001b[0m \u001b[31m808.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('/Users/mankirat/Desktop/ml/ dataset_1 985 rows.csv')\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import requests\n",
    "import json\n",
    "features = [\n",
    "    'avg_loss_making_trades',\n",
    "    'avg_profitable_trades',\n",
    "    'collection_score',\n",
    "    'diamond_hands',\n",
    "    'fear_and_greed_index',\n",
    "    'holder_metrics_score',\n",
    "    'liquidity_score',\n",
    "    'loss_making_trades',\n",
    "    'loss_making_trades_percentage',\n",
    "    'loss_making_volume',\n",
    "    'market_dominance_score',\n",
    "    'metadata_score',\n",
    "    'profitable_trades',\n",
    "    'profitable_trades_percentage',\n",
    "    'profitable_volume',\n",
    "    'token_distribution_score',\n",
    "    'washtrade_index'\n",
    "]\n",
    "\n",
    "X=df[features]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.joblib']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = IsolationForest(\n",
    "    contamination=0.1,  # Assuming 10% of collections might be suspicious\n",
    "    random_state=42,\n",
    "    n_estimators=100\n",
    ")\n",
    "clf.fit(X_scaled)\n",
    "joblib.dump(clf, 'isolation_forest_model.joblib')\n",
    "joblib.dump(scaler, 'scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_risk_score(data: pd.DataFrame, model, scaler) -> Tuple[float, str]:\n",
    "    # Get anomaly scores\n",
    "    score = model.score_samples(scaler.transform(data))\n",
    "    \n",
    "    # Add small epsilon to prevent division by zero\n",
    "    epsilon = 1e-10\n",
    "    \n",
    "    # Handle edge case where min and max scores are equal\n",
    "    score_range = score.max() - score.min()\n",
    "    if abs(score_range) < epsilon:\n",
    "        risk_score = 50.0  # default mid-range risk when all scores are identical\n",
    "    else:\n",
    "        # Normalize scores to 0-100 range with epsilon\n",
    "        risk_score = 100 * (1 - (score - score.min()) / (score_range + epsilon))\n",
    "    \n",
    "    # Determine risk category\n",
    "    if risk_score < 30:\n",
    "        category = \"Low Risk\"\n",
    "    elif risk_score < 70:\n",
    "        category = \"Medium Risk\"\n",
    "    else:\n",
    "        category = \"High Risk\"\n",
    "        \n",
    "    return float(risk_score), category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_risk(new_contract_data):\n",
    "#     # Load saved models\n",
    "#     clf = joblib.load('isolation_forest_model.joblib')\n",
    "#     scaler = joblib.load('scaler.joblib')\n",
    "    \n",
    "#     # Ensure new_contract_data has the same features in the same order\n",
    "#     new_data = pd.DataFrame([new_contract_data], columns=features)\n",
    "    \n",
    "#     # Calculate risk score and category\n",
    "#     risk_score, risk_category = calculate_risk_score(new_data, clf, scaler)\n",
    "    \n",
    "#     return {\n",
    "#         'risk_score': round(risk_score, 2),\n",
    "#         'risk_category': risk_category,\n",
    "#         'contributing_factors': identify_risk_factors(new_data)\n",
    "#     }\n",
    "def predict_risk(contract_dict):\n",
    "    try:\n",
    "        # Load saved models\n",
    "        clf = joblib.load('isolation_forest_model.joblib')\n",
    "        scaler = joblib.load('scaler.joblib')\n",
    "        \n",
    "        # Convert dictionary to DataFrame with proper structure\n",
    "        df_data = pd.DataFrame([contract_dict])\n",
    "        \n",
    "        # Ensure all required features are present\n",
    "        if not all(feature in df_data.columns for feature in features):\n",
    "            missing = set(features) - set(df_data.columns)\n",
    "            raise ValueError(f\"Missing required features: {missing}\")\n",
    "            \n",
    "        # Reorder columns to match model features\n",
    "        new_data = df_data[features]\n",
    "        \n",
    "        # Calculate risk score and category\n",
    "        risk_score, risk_category = calculate_risk_score(new_data, clf, scaler)\n",
    "        \n",
    "        return {\n",
    "            'risk_score': round(risk_score, 2),\n",
    "            'risk_category': risk_category,\n",
    "            'contributing_factors': identify_risk_factors(new_data)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in risk prediction: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_risk_factors(data):\n",
    "    risk_factors = []\n",
    "    \n",
    "    # Define thresholds for various metrics\n",
    "    if data['washtrade_index'].iloc[0] > 50:\n",
    "        risk_factors.append('High wash trading activity')\n",
    "    if data['loss_making_trades_percentage'].iloc[0] > 70:\n",
    "        risk_factors.append('High percentage of loss-making trades')\n",
    "    if data['liquidity_score'].iloc[0] < 30:\n",
    "        risk_factors.append('Low liquidity')\n",
    "    if data['holder_metrics_score'].iloc[0] < 40:\n",
    "        risk_factors.append('Poor holder metrics')\n",
    "    \n",
    "    return risk_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def riskify(contract_address):\n",
    "    url = f\"https://api.unleashnfts.com/api/v2/nft/collection/profile?blockchain=ethereum&contract_address={contract_address}&offset=0&limit=100&sort_by=washtrade_index&time_range=all&sort_order=desc\"\n",
    "    headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"x-api-key\": \"19a1634dc850e33607b074bc62da2e19\"\n",
    "        }\n",
    "\n",
    "        # Make the API request\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = json.loads(response.text)['data']\n",
    "    if data is None:\n",
    "        print('data not available')\n",
    "    else:\n",
    "        print(predict_risk(data[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'risk_score': 50.0, 'risk_category': 'Medium Risk', 'contributing_factors': ['High wash trading activity']}\n"
     ]
    }
   ],
   "source": [
    "riskify('0xbc4ca0eda7647a8ab7c2061c2e118a18a936f13d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
